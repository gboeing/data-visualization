{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse-geocode Google location history\n",
    "\n",
    "See [this blog post](http://geoffboeing.com/2016/06/mapping-google-location-history-python/) for my full write-up of this project, or [this one](http://geoffboeing.com/2014/08/reverse-geocode-a-set-of-lat-long-coordinates-to-city-country/) for more about reverse-geocoding with Google.\n",
    "\n",
    "In the previous notebook, we clustered the location history data to reduce the size of the data set. This reduced set was saved as 'location-history-clustered.csv'. Now we'll reverse-geocode it from lat/long to neighborhood, city, state, country. First, this script copies that csv file and renames the copy 'google-history-to-geocode.csv'. It uses this file as our working file to do the reverse-geocoding and takes full advantage of local caching of results to prevent duplicate API calls during multiple runs. As Google limits your IP address to 2,500 requests per day, we might need to do the entire data set in multiple passes. Hence the working file.\n",
    "\n",
    "Sample API request: https://maps.googleapis.com/maps/api/geocode/json?latlng=39.9058153,-86.054788"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, time, requests, json, os.path, logging as lg, datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pause = 0.1 #google limits you to 10 requests per second\n",
    "use_second_geocoder = False #only set True on your last pass, if multiple\n",
    "max_google_requests = 2500 #how many requests to make of google\n",
    "google_requests_count = 0\n",
    "final_output_filename = 'data/google-location-history.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# configure local caching\n",
    "geocode_cache_filename = 'data/reverse_geocode_cache.js'\n",
    "cache_save_frequency = 100\n",
    "requests_count = 0\n",
    "geocode_cache = json.load(open(geocode_cache_filename)) if os.path.isfile(geocode_cache_filename) else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a logger to capture progress\n",
    "log = lg.getLogger('reverse_geocoder')\n",
    "if not getattr(log, 'handler_set', None):\n",
    "    todays_date = dt.datetime.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "    log_filename = 'logs/reverse_geocoder_{}.log'.format(todays_date)\n",
    "    handler = lg.FileHandler(log_filename, encoding='utf-8')\n",
    "    formatter = lg.Formatter('%(asctime)s %(levelname)s %(name)s %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    log.addHandler(handler)\n",
    "    log.setLevel(lg.INFO)\n",
    "    log.handler_set = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up the working file (see note at top of notebook)\n",
    "working_filename = 'data/google-history-to-geocode.csv'\n",
    "if not os.path.isfile(working_filename):\n",
    "    df_temp = pd.read_csv('data/location-history-clustered.csv', encoding='utf-8')\n",
    "    df_temp.to_csv(working_filename, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saves the dict cache to disk as json\n",
    "def save_cache_to_disk(cache, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as cache_file:\n",
    "        cache_file.write(json.dumps(cache))\n",
    "    log.info('saved {:,} cached items to {}'.format(len(cache.keys()), filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a http request\n",
    "def make_request(url):\n",
    "    log.info('requesting {}'.format(url))\n",
    "    return requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parse neighborhood data from a google reverse-geocode result\n",
    "def get_neighborhood_google(result):\n",
    "    if pd.notnull(result):\n",
    "        if 'address_components' in result:\n",
    "            for component in result['address_components']:\n",
    "                if 'neighborhood' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'sublocality_level_1' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'sublocality_level_2' in component['types']:\n",
    "                    return component['long_name']                \n",
    "\n",
    "# parse city data from a google reverse-geocode result\n",
    "# to find city, return the finest-grain address component \n",
    "# google returns these components in order from finest to coarsest grained\n",
    "def get_city_google(result):\n",
    "    if pd.notnull(result):\n",
    "        if 'address_components' in result:\n",
    "            for component in result['address_components']:\n",
    "                if 'locality' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'postal_town' in component['types']:\n",
    "                    return component['long_name']              \n",
    "                elif 'administrative_area_level_5' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'administrative_area_level_4' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'administrative_area_level_3' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'administrative_area_level_2' in component['types']:\n",
    "                    return component['long_name']\n",
    "\n",
    "# parse state data from a google reverse-geocode result                \n",
    "# to find state, you want the lowest-level admin area available\n",
    "# but, google returns admin areas listed from highest-level to lowest\n",
    "# so you can't just return as soon as you find the first match\n",
    "# this is is opposite of the previous, because this time we want the coarsest-grain match\n",
    "# otherwise we end up with counties and so forth instead of states\n",
    "def get_state_google(result):\n",
    "    if pd.notnull(result):\n",
    "        state = None\n",
    "        if 'address_components' in result:\n",
    "            for component in result['address_components']:\n",
    "                if 'administrative_area_level_1' in component['types']:\n",
    "                    state = component['long_name']\n",
    "                elif 'administrative_area_level_2' in component['types']:\n",
    "                    state = component['long_name']\n",
    "                elif 'administrative_area_level_3' in component['types']:\n",
    "                    state = component['long_name']\n",
    "                elif 'locality' in component['types']:\n",
    "                    state = component['long_name']\n",
    "        return state\n",
    "\n",
    "# parse country data from a google reverse-geocode result\n",
    "def get_country_google(result):\n",
    "    if pd.notnull(result):\n",
    "        if 'address_components' in result:\n",
    "            for component in result['address_components']:\n",
    "                if 'country' in component['types']:\n",
    "                    return component['long_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parse city, state, country data from a nominatim reverse-geocode result\n",
    "def parse_nominatim_data(data):\n",
    "    country = None\n",
    "    state = None\n",
    "    city = None\n",
    "    if isinstance(data, dict):\n",
    "        if 'address' in data:\n",
    "            if 'country' in data['address']:\n",
    "                country = data['address']['country']\n",
    "\n",
    "            #state\n",
    "            if 'region' in data['address']:\n",
    "                state = data['address']['region']\n",
    "            if 'state' in data['address']:\n",
    "                state = data['address']['state']\n",
    "\n",
    "            #city\n",
    "            if 'county' in data['address']:\n",
    "                county = data['address']['county']\n",
    "            if 'village' in data['address']:\n",
    "                city = data['address']['village']\n",
    "            if 'city' in data['address']:\n",
    "                city = data['address']['city']\n",
    "    return city, state, country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pass latlng data to osm nominatim to reverse geocode it\n",
    "def reverse_geocode_nominatim(latlng):\n",
    "\n",
    "    time.sleep(pause)\n",
    "    url = 'https://nominatim.openstreetmap.org/reverse?format=json&lat={}&lon={}&zoom=18&addressdetails=1'\n",
    "    data = make_request(url.format(latlng.split(',')[0], latlng.split(',')[1]))\n",
    "\n",
    "    place = {}\n",
    "    place['neighborhood'] = None\n",
    "    place['city'], place['state'], place['country'] = parse_nominatim_data(data)\n",
    "    return place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pass the Google API latlng data to reverse geocode it\n",
    "def reverse_geocode_google(latlng):\n",
    "    \n",
    "    global google_requests_count\n",
    "    \n",
    "    if google_requests_count < max_google_requests:\n",
    "        # we have not yet made the max # of requests\n",
    "        time.sleep(pause)\n",
    "        google_requests_count += 1\n",
    "        url = 'https://maps.googleapis.com/maps/api/geocode/json?latlng={}'\n",
    "        data = make_request(url.format(latlng))\n",
    "        if len(data['results']) > 0:\n",
    "            result = data['results'][0]\n",
    "            \n",
    "            place = {}\n",
    "            place['neighborhood'] = get_neighborhood_google(result)\n",
    "            place['city'] = get_city_google(result)\n",
    "            place['state'] = get_state_google(result)\n",
    "            place['country'] = get_country_google(result)\n",
    "            return place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reverse_geocode(latlng, reverse_geocode_function=reverse_geocode_google, use_cache=True):\n",
    "    \n",
    "    global geocode_cache, requests_count\n",
    "    \n",
    "    if use_cache and latlng in geocode_cache and pd.notnull(geocode_cache[latlng]):\n",
    "        log.info('retrieving results from cache for lat-long \"{}\"'.format(latlng))\n",
    "        return geocode_cache[latlng]\n",
    "    else:\n",
    "        place = reverse_geocode_function(latlng)\n",
    "        geocode_cache[latlng] = place\n",
    "        log.info('stored place details in cache for lat-long \"{}\"'.format(latlng))\n",
    "        \n",
    "        requests_count += 1\n",
    "        if requests_count % cache_save_frequency == 0: \n",
    "            save_cache_to_disk(geocode_cache, geocode_cache_filename)\n",
    "            \n",
    "        return place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_place_by_latlng(latlng, component):\n",
    "    try:\n",
    "        return place_dict[latlng][component]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep the data for geocoding\n",
    "\n",
    "If there are more than 2,500 rows in the dataset, you need to run this notebook multiple times because Google limits you to 2,500 requests per day. Or fall back on the nominatim API, with `use_second_geocoder=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,149 rows in dataset\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(working_filename, encoding='utf-8')\n",
    "print('{:,} rows in dataset'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>timestamp_s</th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.863151</td>\n",
       "      <td>-122.273774</td>\n",
       "      <td>1381094629</td>\n",
       "      <td>2013-10-06 21:23:49</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.878138</td>\n",
       "      <td>100.242087</td>\n",
       "      <td>1432343754</td>\n",
       "      <td>2015-05-23 01:15:54</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.522827</td>\n",
       "      <td>9.054906</td>\n",
       "      <td>1402128471</td>\n",
       "      <td>2014-06-07 08:07:51</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.309692</td>\n",
       "      <td>-111.902135</td>\n",
       "      <td>1419581216</td>\n",
       "      <td>2014-12-26 08:06:56</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-33.893208</td>\n",
       "      <td>151.215002</td>\n",
       "      <td>1464539101</td>\n",
       "      <td>2016-05-29 16:25:01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat         lon  timestamp_s             datetime  city state  \\\n",
       "0  37.863151 -122.273774   1381094629  2013-10-06 21:23:49  None  None   \n",
       "1  26.878138  100.242087   1432343754  2015-05-23 01:15:54  None  None   \n",
       "2  48.522827    9.054906   1402128471  2014-06-07 08:07:51  None  None   \n",
       "3  33.309692 -111.902135   1419581216  2014-12-26 08:06:56  None  None   \n",
       "4 -33.893208  151.215002   1464539101  2016-05-29 16:25:01  None  None   \n",
       "\n",
       "  country neighborhood  \n",
       "0    None         None  \n",
       "1    None         None  \n",
       "2    None         None  \n",
       "3    None         None  \n",
       "4    None         None  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create city, state, country columns only if they don't already exist\n",
    "new_cols = ['city', 'state', 'country', 'neighborhood']\n",
    "for col in new_cols:\n",
    "    if not col in df.columns:\n",
    "        df[col] = None\n",
    "        \n",
    "# drop the locations and timestamp_ms columns if they are still here\n",
    "cols_to_remove = ['locations', 'timestamp_ms']\n",
    "for col in cols_to_remove:\n",
    "    if col in df.columns:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "        \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put latlng in the format google likes so it's easy to call their api\n",
    "# and round to 7 decimal places so our cache's keys are consistent\n",
    "# (so you don't get weird float precision artifacts like 114.1702368000000001)\n",
    "df['latlng'] = df.apply(lambda row: '{:.7f},{:.7f}'.format(row['lat'], row['lon']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,149 out of 4,149 rows lack reverse-geocode results\n",
      "We will attempt to reverse-geocode up to 2,500 rows with Google\n"
     ]
    }
   ],
   "source": [
    "mask = pd.isnull(df['country']) & pd.isnull(df['state']) & pd.isnull(df['city']) & pd.isnull(df['neighborhood'])\n",
    "ungeocoded_rows = df[mask]\n",
    "print('{:,} out of {:,} rows lack reverse-geocode results'.format(len(ungeocoded_rows), len(df)))\n",
    "print('We will attempt to reverse-geocode up to {:,} rows with Google'.format(max_google_requests))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Now reverse-geocode the location history with the Google API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_latlngs = df['latlng'].dropna().sort_values().unique()\n",
    "place_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for latlng in unique_latlngs:\n",
    "    place_dict[latlng] = reverse_geocode(latlng, reverse_geocode_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for component in ['country', 'state', 'city', 'neighborhood']:\n",
    "    df[component] = df['latlng'].apply(get_place_by_latlng, args=(component,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 4,149 rows still lack reverse-geocode results\n"
     ]
    }
   ],
   "source": [
    "mask = pd.isnull(df['country']) & pd.isnull(df['state']) & pd.isnull(df['city']) & pd.isnull(df['neighborhood'])\n",
    "ungeocoded_rows = df[mask]\n",
    "print('{:,} out of {:,} rows still lack reverse-geocode results'.format(len(ungeocoded_rows), len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next reverse-geocode missing rows with the Nominatim API\n",
    "\n",
    "If use_second_geocoder is True, use OSM Nominatum API to reverse-geocode any remaining missing rows. Only do this on the final pass. This is useful for places like Kosovo that Google does not return results for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if use_second_geocoder:\n",
    "    unique_latlngs = ungeocoded_rows['latlng'].dropna().sort_values().unique()\n",
    "    for latlng in unique_latlngs:\n",
    "        place_dict[latlng] = reverse_geocode(latlng, reverse_geocode_nominatim)\n",
    "    for component in ['country', 'state', 'city', 'neighborhood']:\n",
    "        df[component] = df['latlng'].apply(get_place_by_latlng, args=(component,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 4,149 rows still lack reverse-geocode results\n"
     ]
    }
   ],
   "source": [
    "mask = pd.isnull(df['country']) & pd.isnull(df['state']) & pd.isnull(df['city']) & pd.isnull(df['neighborhood'])\n",
    "ungeocoded_rows = df[mask]\n",
    "print('{:,} out of {:,} rows still lack reverse-geocode results'.format(len(ungeocoded_rows), len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done: Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>timestamp_s</th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>latlng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4144</th>\n",
       "      <td>33.999645</td>\n",
       "      <td>-118.429866</td>\n",
       "      <td>1356999532</td>\n",
       "      <td>2013-01-01 00:18:52</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "      <td>Culver - West</td>\n",
       "      <td>33.9996450,-118.4298660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>-25.944350</td>\n",
       "      <td>131.948400</td>\n",
       "      <td>1465096999</td>\n",
       "      <td>2016-06-05 03:23:19</td>\n",
       "      <td>Petermann</td>\n",
       "      <td>Northern Territory</td>\n",
       "      <td>Australia</td>\n",
       "      <td>None</td>\n",
       "      <td>-25.9443505,131.9484000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>34.016627</td>\n",
       "      <td>-118.822084</td>\n",
       "      <td>1451757098</td>\n",
       "      <td>2016-01-02 17:51:38</td>\n",
       "      <td>Malibu</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "      <td>Western Malibu</td>\n",
       "      <td>34.0166268,-118.8220838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>34.135661</td>\n",
       "      <td>-117.589982</td>\n",
       "      <td>1451521198</td>\n",
       "      <td>2015-12-31 00:19:58</td>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>34.1356612,-117.5899818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>38.452652</td>\n",
       "      <td>-121.849864</td>\n",
       "      <td>1429388120</td>\n",
       "      <td>2015-04-18 20:15:20</td>\n",
       "      <td>Dixon</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>38.4526520,-121.8498639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat         lon  timestamp_s             datetime  \\\n",
       "4144  33.999645 -118.429866   1356999532  2013-01-01 00:18:52   \n",
       "4145 -25.944350  131.948400   1465096999  2016-06-05 03:23:19   \n",
       "4146  34.016627 -118.822084   1451757098  2016-01-02 17:51:38   \n",
       "4147  34.135661 -117.589982   1451521198  2015-12-31 00:19:58   \n",
       "4148  38.452652 -121.849864   1429388120  2015-04-18 20:15:20   \n",
       "\n",
       "                  city               state        country    neighborhood  \\\n",
       "4144       Los Angeles          California  United States   Culver - West   \n",
       "4145         Petermann  Northern Territory      Australia            None   \n",
       "4146            Malibu          California  United States  Western Malibu   \n",
       "4147  Rancho Cucamonga          California  United States            None   \n",
       "4148             Dixon          California  United States            None   \n",
       "\n",
       "                       latlng  \n",
       "4144  33.9996450,-118.4298660  \n",
       "4145  -25.9443505,131.9484000  \n",
       "4146  34.0166268,-118.8220838  \n",
       "4147  34.1356612,-117.5899818  \n",
       "4148  38.4526520,-121.8498639  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save cache to disk\n",
    "save_cache_to_disk(geocode_cache, geocode_cache_filename)\n",
    "\n",
    "# save the entire data set to the working file\n",
    "df.to_csv(working_filename, encoding='utf-8', index=False)\n",
    "\n",
    "# save the useful columns to a final output file\n",
    "cols_to_retain = ['datetime', 'neighborhood', 'city', 'state', 'country', 'lat', 'lon']\n",
    "df[cols_to_retain].to_csv(final_output_filename, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
