{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MusicBrainz artist lookup\n",
    "\n",
    "To see this analysis live, check out my article [\"Analyzing Last.fm Listening History\"](http://geoffboeing.com/2016/05/analyzing-lastfm-history/)\n",
    "\n",
    "Get artist information, including place name, for each artist that has a music brainz id in my data set generated by the [lastfm_downloader](lastfm_downloader.ipynb).\n",
    "\n",
    "Documentation:\n",
    " - Web service: https://wiki.musicbrainz.org/Development/XML_Web_Service/Version_2/Search\n",
    " - Artist entities: https://musicbrainz.org/doc/Artist\n",
    " - Area entities: https://musicbrainz.org/doc/Area\n",
    "\n",
    "Sample queries:\n",
    " - Artist: https://musicbrainz.org/ws/2/artist/d4659efb-b8eb-4f03-95e9-f69ce35967a9\n",
    " - Area: https://musicbrainz.org/ws/2/area/0a70f24b-1263-4341-8d70-17b8df84154f?inc=area-rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, requests, time, json, os.path\n",
    "import logging as lg, datetime as dt\n",
    "from keys import mb_user_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pause_standard = 1.1\n",
    "pause_exceeded_rate = 2\n",
    "\n",
    "# where to save the csv output\n",
    "csv_filename = 'data/mb.csv'\n",
    "\n",
    "# configure URLs and user-agent header\n",
    "artist_name_url = 'https://musicbrainz.org/ws/2/artist/?query=artist:{}&fmt=json'\n",
    "artist_id_url = 'https://musicbrainz.org/ws/2/artist/{}?fmt=json'\n",
    "area_id_url = 'https://musicbrainz.org/ws/2/area/{}?inc=area-rels&fmt=json'\n",
    "headers = {'User-Agent':mb_user_agent}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# configure local caching\n",
    "area_cache_filename = 'data/area_cache.js'\n",
    "artist_cache_filename = 'data/artist_cache.js'\n",
    "cache_save_frequency = 10\n",
    "area_requests_count = 0\n",
    "artist_requests_count = 0\n",
    "area_cache = json.load(open(area_cache_filename)) if os.path.isfile(area_cache_filename) else {}\n",
    "artist_cache = json.load(open(artist_cache_filename)) if os.path.isfile(artist_cache_filename) else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a logger to capture progress\n",
    "log = lg.getLogger('mb')\n",
    "if not getattr(log, 'handler_set', None):\n",
    "    todays_date = dt.datetime.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "    log_filename = 'logs/mb_{}.log'.format(todays_date)\n",
    "    handler = lg.FileHandler(log_filename, encoding='utf-8')\n",
    "    formatter = lg.Formatter('%(asctime)s %(levelname)s %(name)s %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    log.addHandler(handler)\n",
    "    log.setLevel(lg.INFO)\n",
    "    log.handler_set = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a http request to musicbrainz api and return the result\n",
    "def make_request(url, headers=headers, attempt_count=1):\n",
    "    \n",
    "    global pause_standard\n",
    "    \n",
    "    time.sleep(pause_standard)\n",
    "    log.info('request: {}'.format(url))\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "    except Exception as e:\n",
    "        log.error('requests.get failed: {} {} {}'.format(type(e), e, response.json()))\n",
    "        \n",
    "    if response.status_code == 200: #if status OK\n",
    "        return {'status_code':response.status_code, 'json':response.json()}\n",
    "    \n",
    "    elif response.status_code == 503: #if status error (server busy or rate limit exceeded)\n",
    "        try:\n",
    "            if 'exceeding the allowable rate limit' in response.json()['error']:\n",
    "                #pause_standard = pause_standard + 0.1\n",
    "                log.warning('exceeded allowable rate limit, pause_standard is now {} seconds'.format(pause_standard))\n",
    "                log.warning('details: {}'.format(response.json()))\n",
    "                time.sleep(pause_exceeded_rate)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        next_attempt_count = attempt_count + 1\n",
    "        log.warning('request failed with status_code 503, so we will try it again with attempt #{}'.format(next_attempt_count))\n",
    "        return make_request(url, attempt_count=next_attempt_count)\n",
    "    \n",
    "    else: #if other status code, display info and return None for caller to handle\n",
    "        log.error('make_request failed: status_code {} {}'.format(response.status_code, response.json()))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query the musicbrainz api for an artist's name and return the resulting id\n",
    "def get_artist_id_by_name(name):\n",
    "    response = make_request(artist_name_url.format(name))\n",
    "    try:\n",
    "        if response is not None:\n",
    "            result = response['json']\n",
    "            artist_id = result['artists'][0]['id']\n",
    "            return artist_id\n",
    "    except:\n",
    "        log.error('get_artist_id_by_name error: {}'.format(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_artist_details_from_response(response):\n",
    "    try:\n",
    "        if response is not None:\n",
    "            result = response['json']\n",
    "            artist_details = {'id':result['id'],\n",
    "                              'name':result['name'],            \n",
    "                              'type':result['type'],\n",
    "                              'gender':result['gender'],\n",
    "                              'country':result['country'],\n",
    "                              'begin_date':None,\n",
    "                              'end_date':None,\n",
    "                              'area_id':None,\n",
    "                              'area_name':None,\n",
    "                              'begin_area_id':None,\n",
    "                              'begin_area_name':None,\n",
    "                              'place_id':None,\n",
    "                              'place':None}\n",
    "\n",
    "            if result['life-span'] is not None and 'begin' in result['life-span'] and 'end' in result['life-span']:\n",
    "                artist_details['begin_date'] = result['life-span']['begin']\n",
    "                artist_details['end_date'] = result['life-span']['end']\n",
    "            if result['area'] is not None and 'id' in result['area'] and 'name' in result['area']:\n",
    "                artist_details['area_id'] = result['area']['id']\n",
    "                artist_details['area_name'] = result['area']['name']\n",
    "            if result['begin_area'] is not None and 'id' in result['begin_area'] and 'name' in result['begin_area']:\n",
    "                artist_details['begin_area_id'] = result['begin_area']['id']\n",
    "                artist_details['begin_area_name'] = result['begin_area']['name']\n",
    "            \n",
    "            # populate place with begin_area_name if it's not null, else area_name if it's not null, else None\n",
    "            if artist_details['begin_area_name'] is not None:\n",
    "                artist_details['place'] = artist_details['begin_area_name']\n",
    "                artist_details['place_id'] = artist_details['begin_area_id']\n",
    "            elif artist_details['area_name'] is not None:\n",
    "                artist_details['place'] = artist_details['area_name']\n",
    "                artist_details['place_id'] = artist_details['area_id']\n",
    "            \n",
    "            return artist_details\n",
    "    \n",
    "    except:\n",
    "        log.error('get_artist_by_id error: {}'.format(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get an artist object from the musicbrainz api by the musicbrainz artist id\n",
    "def get_artist_by_id(artist_id):\n",
    "    \n",
    "    global artist_cache, artist_requests_count\n",
    "    \n",
    "    # first, get the artist details either from the cache or from the API\n",
    "    if artist_id in artist_cache:\n",
    "        # if we've looked up this ID before, get it from the cache\n",
    "        log.info('retrieving artist details from cache for ID {}'.format(artist_id))\n",
    "        artist_details = artist_cache[artist_id]\n",
    "    else:\n",
    "        # if we haven't looked up this ID before, look it up from API now\n",
    "        response = make_request(artist_id_url.format(artist_id))\n",
    "        artist_details = extract_artist_details_from_response(response)\n",
    "        \n",
    "        # add this artist to the cache so we don't have to ask the API for it again\n",
    "        artist_cache[artist_id] = artist_details \n",
    "        log.info('adding artist details to cache for ID {}'.format(artist_id))\n",
    "        \n",
    "        # save the artist cache to disk once per every cache_save_frequency API requests\n",
    "        artist_requests_count += 1\n",
    "        if artist_requests_count % cache_save_frequency == 0: save_cache_to_disk(artist_cache, artist_cache_filename)\n",
    "    \n",
    "    # now that we have the artist details...\n",
    "    return artist_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a dataframe of artist details and place info from a list of artist IDs\n",
    "def make_artists_df(artist_ids, row_labels=None, df=None, csv_save_frequency=100):\n",
    "    \n",
    "    # create a list of row labels if caller didn't pass one in\n",
    "    if row_labels is None:\n",
    "        row_labels = range(len(artist_ids))\n",
    "    \n",
    "    # create a new dataframe if caller didn't pass an existing one in\n",
    "    cols = ['id', 'name', 'type', 'gender', 'country', 'begin_date', 'end_date', \n",
    "            'begin_area_id', 'begin_area_name', 'area_id', 'area_name', 'place_id', 'place']\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        df = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for artist_id, n in zip(artist_ids, row_labels):\n",
    "        try:\n",
    "            # get the artist info object\n",
    "            artist = get_artist_by_id(artist_id)\n",
    "\n",
    "            # create (or update) a df row containing the data from this artist object\n",
    "            df.loc[n] = [ artist[col] for col in cols ]\n",
    "            log.info('successfully got artist details #{:,}: artist_id={}'.format(n, artist_id))\n",
    "            \n",
    "            # save csv dataset to disk once per every csv_save_frequency rows\n",
    "            if n % csv_save_frequency == 0: df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "            \n",
    "        except Exception as e:\n",
    "            log.error('row #{} failed: {}'.format(n, e))\n",
    "            pass\n",
    "    \n",
    "    df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "    finish_time = time.time()\n",
    "    message = 'processed {:,} artists in {:,} seconds and saved csv'.format(len(artist_ids), round(finish_time-start_time, 2))\n",
    "    log.info(message)\n",
    "    print(message)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_area_details_from_response(response):\n",
    "    area_details = {}\n",
    "    try:\n",
    "        area_details['name'] = response['json']['name']\n",
    "        if 'relations' in response['json']:\n",
    "            for relation in response['json']['relations']:\n",
    "                if relation['direction']=='backward' and relation['type']=='part of':\n",
    "                    area_details['parent_id'] = relation['area']['id']\n",
    "                    area_details['parent_name'] = relation['area']['name']\n",
    "        else:\n",
    "            log.warning('area returned no relations: {}'.format(result))\n",
    "        return area_details\n",
    "    except Exception as e:\n",
    "        log.error('extract_area_details_from_response failed: {}'.format(response))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get details of an 'area' from the musicbrainz api by area id\n",
    "def get_area(area_id, full_area_str=''):\n",
    "    \n",
    "    global area_cache, area_requests_count\n",
    "    \n",
    "    # first, get the area details either from the cache or from the API\n",
    "    if area_id in area_cache:\n",
    "        # if we've looked up this ID before, get it from the cache\n",
    "        log.info('retrieving area details from cache for ID {}'.format(area_id))\n",
    "        area_details = area_cache[area_id]\n",
    "    else:\n",
    "        # if we haven't looked up this ID before, look it up from API now\n",
    "        response = make_request(area_id_url.format(area_id))\n",
    "        area_details = extract_area_details_from_response(response)\n",
    "        \n",
    "        # add this area to the cache so we don't have to ask the API for it again\n",
    "        area_cache[area_id] = area_details \n",
    "        log.info('adding area details to cache for ID {}'.format(area_id))\n",
    "        \n",
    "        # save the area cache to disk once per every cache_save_frequency API requests\n",
    "        area_requests_count += 1\n",
    "        if area_requests_count % cache_save_frequency == 0: save_cache_to_disk(area_cache, area_cache_filename)\n",
    "    \n",
    "    # now that we have the area details...\n",
    "    try:\n",
    "        if full_area_str == '': \n",
    "            full_area_str = area_details['name']\n",
    "        if 'parent_name' in area_details and 'parent_id' in area_details:\n",
    "            full_area_str = '{}, {}'.format(full_area_str, area_details['parent_name'])\n",
    "            return area_details['parent_id'], full_area_str #recursively get parent's details\n",
    "        else:\n",
    "            # if no parents exist, we're done\n",
    "            return None, full_area_str\n",
    "    except Exception as e:\n",
    "        log.error('get_area error: {}'.format(e)) \n",
    "        return None, full_area_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construct a full name from an area ID\n",
    "# recursively traverse the API, getting coarser-grained place details each time until top-level country\n",
    "def get_place_full_name_by_area_id(area_id):\n",
    "    area_name=''\n",
    "    while area_id is not None:\n",
    "        area_id, area_name = get_area(area_id, area_name)\n",
    "    return area_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take a list of place IDs and return a dict linking each to its constructed full name\n",
    "def get_place_full(unique_place_ids):\n",
    "    start_time = time.time()\n",
    "    message = 'we will attempt to get place full names for {:,} place IDs'.format(len(unique_place_ids))\n",
    "    log.info(message)\n",
    "    print(message)\n",
    "    \n",
    "    place_ids_names = {}\n",
    "    for place_id, n in zip(unique_place_ids, range(len(unique_place_ids))):\n",
    "        try:\n",
    "            place_name = get_place_full_name_by_area_id(place_id)\n",
    "        except:\n",
    "            place_name = None\n",
    "        place_ids_names[place_id] = place_name\n",
    "        log.info('successfully created place #{:,}: \"{}\" from place ID \"{}\"'.format(n + 1, place_name, place_id))\n",
    "    \n",
    "    message = 'finished getting place full names from place IDs in {:.2f} seconds'.format(time.time()-start_time)\n",
    "    log.info(message)\n",
    "    print(message)\n",
    "    return place_ids_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find place id in dict and return its constructed full name\n",
    "def get_place_full_from_dict(place_id):\n",
    "    try:\n",
    "        return place_ids_names[place_id]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_cache_to_disk(cache, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as cache_file:\n",
    "        cache_file.write(json.dumps(cache))\n",
    "    log.info('saved {:,} cached items to {}'.format(len(cache.keys()), filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it with a demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo test finished in 2.63 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Brixton, Lambeth, London, England, United Kingdom'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where is david bowie from?\n",
    "name = 'david bowie'\n",
    "start_time = time.time()\n",
    "artist_id = get_artist_id_by_name(name)\n",
    "artist = get_artist_by_id(artist_id)\n",
    "artist['place_full'] = get_place_full_name_by_area_id(artist['place_id'])\n",
    "message = 'demo test finished in {:.2f} seconds'.format(time.time()-start_time)\n",
    "log.info(message)\n",
    "print(message)\n",
    "artist['place_full']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log.info('musicbrainz downloader script started')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 13,720 unique artists to get details for\n"
     ]
    }
   ],
   "source": [
    "# load the artist IDs from the lastfm scrobble history data set\n",
    "scrobbles = pd.read_csv('data/lastfm_scrobbles.csv', encoding='utf-8')\n",
    "artist_ids = scrobbles['artist_mbid'].dropna().unique()#[1000:1005]\n",
    "message = 'there are {:,} unique artists to get details for'.format(len(artist_ids))\n",
    "log.info(message)\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 13,720 artists in 84.53 seconds and saved csv\n"
     ]
    }
   ],
   "source": [
    "df = make_artists_df(artist_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-try any failed rows one more time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 artists to retry\n"
     ]
    }
   ],
   "source": [
    "# get all the row labels missing in the df (due to errors that prevented row creation)\n",
    "missing_row_labels = [ label for label in range(len(artist_ids)) if label not in df.index ]\n",
    "\n",
    "# get the artist mbid for each\n",
    "row_labels_to_retry = sorted(missing_row_labels)\n",
    "artist_ids_to_retry = [ artist_ids[label] for label in row_labels_to_retry ]\n",
    "\n",
    "message = '{} artists to retry'.format(len(artist_ids_to_retry))\n",
    "log.info(message)\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 4 artists in 0.1 seconds and saved csv\n"
     ]
    }
   ],
   "source": [
    "df = make_artists_df(artist_ids_to_retry, row_labels_to_retry, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>place_id</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>殷承宗</td>\n",
       "      <td>7c81bb69-a99b-3487-b6d4-0f76d7a29ca0</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>小宮瑞代</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boys of Scandinavia</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Majorstuen</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Li He</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name                              place_id  place\n",
       "0                  殷承宗  7c81bb69-a99b-3487-b6d4-0f76d7a29ca0  China\n",
       "1                 小宮瑞代                                  None   None\n",
       "2  Boys of Scandinavia                                  None   None\n",
       "3           Majorstuen                                  None   None\n",
       "4                Li He                                  None   None"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save to csv and show a snippet\n",
    "df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "df[['name', 'place_id', 'place']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now get full place name for each unique place ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we will attempt to get place full names for 2,193 place IDs\n",
      "finished getting place full names from place IDs in 1.17 seconds\n"
     ]
    }
   ],
   "source": [
    "unique_place_ids = df['place_id'].dropna().unique()\n",
    "place_ids_names = get_place_full(unique_place_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>place_id</th>\n",
       "      <th>place</th>\n",
       "      <th>place_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>殷承宗</td>\n",
       "      <td>7c81bb69-a99b-3487-b6d4-0f76d7a29ca0</td>\n",
       "      <td>China</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>小宮瑞代</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boys of Scandinavia</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Majorstuen</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Li He</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name                              place_id  place place_full\n",
       "0                  殷承宗  7c81bb69-a99b-3487-b6d4-0f76d7a29ca0  China      China\n",
       "1                 小宮瑞代                                  None   None       None\n",
       "2  Boys of Scandinavia                                  None   None       None\n",
       "3           Majorstuen                                  None   None       None\n",
       "4                Li He                                  None   None       None"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['place_full'] = df['place_id'].map(get_place_full_from_dict)\n",
    "df[['name', 'place_id', 'place', 'place_full']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All done - wrap up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows are missing place_full but have place_id\n",
      "4 row labels are missing in the df\n"
     ]
    }
   ],
   "source": [
    "# OK, one final check - see how many artist ids did not make it into the final dataframe\n",
    "# first get all the rows missing place_full that have place_id\n",
    "mask = (pd.isnull(df['place_full'])) & (pd.notnull(df['place_id']))\n",
    "rows_missing_place_full = list(df[mask].index)\n",
    "\n",
    "# then get all the row labels missing in the df (due to errors that prevented row creation)\n",
    "missing_row_labels = [ label for label in range(len(artist_ids)) if label not in df.index ]\n",
    "\n",
    "message = '{} rows are missing place_full but have place_id'.format(len(rows_missing_place_full))\n",
    "log.info(message)\n",
    "print(message)\n",
    "message = '{} row labels are missing in the df'.format(len(missing_row_labels))\n",
    "log.info(message)\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# finish by saving the csv and cache files to disk\n",
    "df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "save_cache_to_disk(area_cache, area_cache_filename)\n",
    "save_cache_to_disk(artist_cache, artist_cache_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
